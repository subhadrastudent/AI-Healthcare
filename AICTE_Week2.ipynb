{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPpjErSc3lbJddVCEYk8Y9j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/subhadrastudent/AICTE_Forest_Fire_Detection_2025/blob/main/AICTE_Week2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HXV7ypdxIezO"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------\n",
        "# Step 1: Download & Explore Dataset\n",
        "# ----------------------------------\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"elmadafri/the-wildfire-dataset\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# ----------------------------------\n",
        "# Step 2: Import Required Libraries\n",
        "# ----------------------------------\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# ----------------------------------\n",
        "# Step 3: GPU Check\n",
        "# ----------------------------------\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "    print(\"âœ… GPU Available\")\n",
        "else:\n",
        "    print(\"âš ï¸ GPU Unavailable\")\n",
        "\n",
        "# ----------------------------------\n",
        "# Step 4: Define Data Paths\n",
        "# ----------------------------------\n",
        "train_dir = '/kaggle/input/the-wildfire-dataset/the_wildfire_dataset_2n_version/train'\n",
        "val_dir = '/kaggle/input/the-wildfire-dataset/the_wildfire_dataset_2n_version/val'\n",
        "test_dir = '/kaggle/input/the-wildfire-dataset/the_wildfire_dataset_2n_version/test'\n",
        "\n",
        "classes = os.listdir(train_dir)\n",
        "print(f\"Classes: {classes}\")\n",
        "\n",
        "# ----------------------------------\n",
        "# Step 5: Data Augmentation & Generator\n",
        "# ----------------------------------\n",
        "img_size = (150, 150)\n",
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, target_size=img_size, batch_size=batch_size, class_mode='binary', shuffle=True)\n",
        "\n",
        "val_generator = val_test_datagen.flow_from_directory(\n",
        "    val_dir, target_size=img_size, batch_size=batch_size, class_mode='binary', shuffle=False)\n",
        "\n",
        "test_generator = val_test_datagen.flow_from_directory(\n",
        "    test_dir, target_size=img_size, batch_size=batch_size, class_mode='binary', shuffle=False)\n",
        "\n",
        "# ----------------------------------\n",
        "# Step 6: Model Architecture\n",
        "# ----------------------------------\n",
        "model = Sequential([\n",
        "    Input(shape=(150, 150, 3)),\n",
        "\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# ----------------------------------\n",
        "# Step 7: Callbacks\n",
        "# ----------------------------------\n",
        "checkpoint_cb = ModelCheckpoint(\"best_fire_model.h5\", save_best_only=True, monitor='val_loss')\n",
        "earlystop_cb = EarlyStopping(patience=5, restore_best_weights=True)\n",
        "\n",
        "# ----------------------------------\n",
        "# Step 8: Train Model\n",
        "# ----------------------------------\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=20,\n",
        "    callbacks=[checkpoint_cb, earlystop_cb]\n",
        ")\n",
        "\n",
        "# ----------------------------------\n",
        "# Step 9: Evaluate Model\n",
        "# ----------------------------------\n",
        "loss, acc = model.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {acc:.2f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred_labels = (y_pred > 0.5).astype(int).flatten()\n",
        "y_true = test_generator.classes\n",
        "\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred_labels, target_names=classes))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred_labels)\n",
        "sns.heatmap(cm, annot=True, fmt='d', xticklabels=classes, yticklabels=classes, cmap='Blues')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# ----------------------------------\n",
        "# Step 10: Fire Alert System (Sample)\n",
        "# ----------------------------------\n",
        "def predict_fire(image_path):\n",
        "    from tensorflow.keras.preprocessing import image\n",
        "    img = image.load_img(image_path, target_size=img_size)\n",
        "    img_array = image.img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    prediction = model.predict(img_array)[0][0]\n",
        "    if prediction > 0.5:\n",
        "        print(\"ðŸ”¥ Alert: Forest Fire Detected!\")\n",
        "    else:\n",
        "        print(\"ðŸŒ² Safe: No Fire Detected.\")\n",
        "\n",
        "# Example usage:\n",
        "# predict_fire('/path/to/test/image.jpg')\n"
      ]
    }
  ]
}